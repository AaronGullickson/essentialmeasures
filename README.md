# Essential Measures: Ancestry, Race, and Social Difference

The files in this repository will reproduce the analysis used in my paper "Essential Measures: Ancestry, Race, and Social Difference" published in the [American Behavioral Scientist](http://abs.sagepub.com/content/60/4/498). The analysis was performed in Stata, R, and Python on Census and American Community Survey data from [IPUMS](http://www.ipums.org).

## The Data

The data used here were compiled from 1990 and 2000 Census data and American Community Survey data from 2001-2012. The data were extracted from the [IPUMS](http://www.ipums.org) system. Under the terms of the standard IPUMS contract, I am not currently allowed to re-distribute the data. Users can however very easily reproduce my IPUMS extract. The file `rawdata_cbk.txt` contains all the information on which variables and which datasets were included in the extract. Upon downloading the data, the data should be renamed `rawdata_ancestry_ipums.dat`. This is the name that the initial `organizedata.do` script expects. Note that this extract must exactly match the extract described in `rawdata_cbk.txt`. If it does not, the user should download the do-file provided by IPUMS and rename it `rawdata_ancestry_ipums.do` and within that file change the name of the dat file to point to the correct raw data file.

## Running the Programs

The repository includes a bash script entitled `runeverything.sh` that will run the entire analysis. However, in order to use the script properly, users will need to edit it to provide the proper path to a stata executable and will need to have the THOTH python module installed in the same directory (more on that below). Alternatively, users can just run each script separately.All scripts will produce log files that are placed in the `logs` folder and all important output (csv files and stata DTA files) will be placed in an `output` folder. Here is the order in which scripts should be run as well as a description of each script:

1.	 `organizedata.do` - This STATA script will read in the fixed-width data from ipums (`rawdata_ancestry_ipums.dat`) and do all of the important coding and limiting of the data. Most importantly, it will code the ancestry and race data using a variety of categorizations. It will also take care of important sample restrictions. It will produce a final dataset called `fulldata.dta`. It will also produce a slightly different dataset needed for the multivariate models called `modeldata.dta`.

2. `collapsedata.do` - This STATA script will take the `fulldata.dta` produced in step (1) and will then collapse the data to produce distributions of race reporting for a variety of sample restrictions and ancestry groupings. Currently, it uses three different schemes. For each scheme, the program produces a weighted and unweighted version.
	- Single ancestry responses - Each row is a specific single ancestry only for individuals who reported one ancestry. All data from 2000-2012 are combined. These data are output in `raceancestryd_single_2000.csv` and `raceancestryd_single_2000_weighted.csv`.
	- Big racial ancestry responses - Each row is one of the "big race" ancestries (e.g. White, Black). Individuals with multiple ancestry responses are included here and separate rows are recorded for those who report two different racial ancestries (e.g. White/Black). All data from 2000-2012 are combined. These data are output in `raceancestryomb_2000.csv` and `raceancestryomb_2000_weighted.csv`.
	- Big racial ancestry responses by year - This is the same as the big racial ancestry responses except that responses are kept separately by census year (1990, 2000) and three year intervals for ACS data (2001-2003, 2004-
2006, 2007-2009, 2010-2012). These data are output in `raceancestryomb_byyear.csv` and `raceancestryomb_byyear_weighted.csv`.

3. `entropy.py` or `calculate_entropy.R` - This step will read in the CSV files from the previous step and use them to calculate entropy for each row of data. There are two approaches that the user can use here. Regardless of approach, the results are output as CSV files starting with the file name "entropy" in the `output` folder.
 - The approach used in the paper is to use the python script `entropy.py` which utilizes the [THOTH python library](http://tuvalu.santafe.edu/~simon/page7/page7.html) to get bootstrapped estimates of entropy. All sample estimates of entropy suffer from sample bias. It is impossible to remove this sample bias entirely, but the bootstrapping method can substantially correct for it. In this case, that bias is likely to be small as it is generally only large when there are a large number of categories relative to the number of observations. THOTH also has the advantage of estimating 95% confidence intervals for the sample entropy statistics. The downside of THOTH is that it can be difficult to install. I was able to install it on my linux computer, but never had any luck installing it on my Mac laptop. The python script assumes that the `thoth` folder is placed directly in the same directory in which python is run.
 - For users who want a simpler approach or cannot get THOTH to install, the `calculate_entropy.R` R script will calculate entropy in R. Users should install the R package `entropy` prior to running this script in order to get estimates that adjust for sampling bias. In general, the results here are pretty close to the bootstrapped estimates from THOTH but may differ somewhat for small sample size ancestries. This program will not estimate confidence intervals.

4. `createmodeldata.R` - This R script creates the final data for the college completion models by taking `modeldata.dta` applying some additional sample restrictions and creating some additional variables. it also draws a 25% sample of the full data for computational efficiency. I really could have collapsed some of the stuff done here in to earlier scripts but originally it was doing more. The final dataset produced is output as a STATA dta file called `individual.dta` and an R data file called `individual.RData`.

5. `bigmodel.do`  - This Stata script runs the models that parse the deviance for college completion by the different ancestry groups. The output here is used to construct Figure 4 from the article.

6. `multimodels.do` - This Stata script runs the multilevel models that predict college completion separately for each big race group with random effects for individual ancestry groups. The output here is used to construct Figure 5 from the paper.

A final R Markdown file entitled `figures.Rmd` can be run to reproduce the figures from the analysis. Code to reproduce Figures 4 and 5 are provided but users should be aware that the numbers for these figures are hard-coded in and will not change dynamically based on new output because the necessary numbers need to be manually extracted from the appropriate log files for these models.

I include in this repository the CSV files and log files from my latest run of the data, but I do not include the Stata DTA files because of their size. The entropy calculated in this output is based on the THOTH bootstrapping method.
